{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "show = tv.transforms.ToPILImage()  # 将Tensor转化为Image\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(),  # 转为Tensor\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化\n",
    "                                ])\n",
    "# 训练集\n",
    "train_set = tv.datasets.CIFAR10(root='E:\\Data\\dataSet\\cifar-10-python',\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transform)\n",
    "\n",
    "train_loader =torch.utils.data.DataLoader(train_set,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True)\n",
    "#                                           num_workers=1)\n",
    "\n",
    "# 测试集\n",
    "test_set = tv.datasets.CIFAR10(root='E:\\Data\\dataSet\\cifar-10-python',\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=transform)\n",
    "  \n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=False)\n",
    "#                                           num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"输入为3通道的网络\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cba1 = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.LeakyReLU()\n",
    "                    )\n",
    "        self.cba2 = nn.Sequential(\n",
    "                    nn.Conv2d(32, 32, 3, 2, 1),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.LeakyReLU()\n",
    "                    )\n",
    "        self.cba3 = nn.Sequential(\n",
    "                    nn.Conv2d(32, 64, 3, 1, 1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.LeakyReLU()\n",
    "                    )\n",
    "        self.cba4 = nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, 3, 2, 1),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.LeakyReLU()\n",
    "                    )\n",
    "        \n",
    "        \n",
    "#         self.features = nn.ModuleList([self.cba1, self.cba2, self.cba3, self.cba4])\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(4096, 128),  # 规定尺寸大小的输入\n",
    "                    nn.BatchNorm1d(128),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(128, 10),\n",
    "                    nn.Softmax(dim=1)\n",
    "                    ) \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = self.features(x)  # 会报错，Module_List没有实现forward()方法\n",
    "#         for model in self.features:\n",
    "#              x = model(x)\n",
    "        x = self.cba1(x)\n",
    "        x = self.cba2(x)\n",
    "        x = self.cba3(x)\n",
    "        x = self.cba4(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)  # 按照Batch形式排列成[Batch, C*W*H]\n",
    "#         x = nn.Linear(in_features=x.size()[-1], out_features=128)(x)  # 将模型放到cuda上时，在forward()中初始化层会报错；cpu上没问题\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将模型数据放入cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device  # 判断模型位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cuda')\n",
    "net = net.to(device)  # 整个式子等价与net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(4, 3, 32, 32)   # 判断数据位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用torchsummay.summary展示层结构 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cba1.0.weight torch.Size([32, 3, 3, 3])\n",
      "cba1.0.bias torch.Size([32])\n",
      "cba1.1.weight torch.Size([32])\n",
      "cba1.1.bias torch.Size([32])\n",
      "cba2.0.weight torch.Size([32, 32, 3, 3])\n",
      "cba2.0.bias torch.Size([32])\n",
      "cba2.1.weight torch.Size([32])\n",
      "cba2.1.bias torch.Size([32])\n",
      "cba3.0.weight torch.Size([64, 32, 3, 3])\n",
      "cba3.0.bias torch.Size([64])\n",
      "cba3.1.weight torch.Size([64])\n",
      "cba3.1.bias torch.Size([64])\n",
      "cba4.0.weight torch.Size([64, 64, 3, 3])\n",
      "cba4.0.bias torch.Size([64])\n",
      "cba4.1.weight torch.Size([64])\n",
      "cba4.1.bias torch.Size([64])\n",
      "classifier.0.weight torch.Size([128, 4096])\n",
      "classifier.0.bias torch.Size([128])\n",
      "classifier.1.weight torch.Size([128])\n",
      "classifier.1.bias torch.Size([128])\n",
      "classifier.4.weight torch.Size([10, 128])\n",
      "classifier.4.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, p in net.named_parameters():\n",
    "    print(name, p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 32, 32, 32]             896\n",
      "       BatchNorm2d-2            [1, 32, 32, 32]              64\n",
      "         LeakyReLU-3            [1, 32, 32, 32]               0\n",
      "            Conv2d-4            [1, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-5            [1, 32, 16, 16]              64\n",
      "         LeakyReLU-6            [1, 32, 16, 16]               0\n",
      "            Conv2d-7            [1, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-8            [1, 64, 16, 16]             128\n",
      "         LeakyReLU-9            [1, 64, 16, 16]               0\n",
      "           Conv2d-10              [1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11              [1, 64, 8, 8]             128\n",
      "        LeakyReLU-12              [1, 64, 8, 8]               0\n",
      "           Linear-13                   [1, 128]         524,416\n",
      "      BatchNorm1d-14                   [1, 128]             256\n",
      "        LeakyReLU-15                   [1, 128]               0\n",
      "          Dropout-16                   [1, 128]               0\n",
      "           Linear-17                    [1, 10]           1,290\n",
      "          Softmax-18                    [1, 10]               0\n",
      "================================================================\n",
      "Total params: 591,914\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.41\n",
      "Params size (MB): 2.26\n",
      "Estimated Total Size (MB): 3.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model = net, input_size = (3, 32, 32), batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [4, 32, 32, 32]             896\n",
      "       BatchNorm2d-2            [4, 32, 32, 32]              64\n",
      "         LeakyReLU-3            [4, 32, 32, 32]               0\n",
      "            Conv2d-4            [4, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-5            [4, 32, 16, 16]              64\n",
      "         LeakyReLU-6            [4, 32, 16, 16]               0\n",
      "            Conv2d-7            [4, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-8            [4, 64, 16, 16]             128\n",
      "         LeakyReLU-9            [4, 64, 16, 16]               0\n",
      "           Conv2d-10              [4, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11              [4, 64, 8, 8]             128\n",
      "        LeakyReLU-12              [4, 64, 8, 8]               0\n",
      "           Linear-13                   [4, 128]         524,416\n",
      "      BatchNorm1d-14                   [4, 128]             256\n",
      "        LeakyReLU-15                   [4, 128]               0\n",
      "          Dropout-16                   [4, 128]               0\n",
      "           Linear-17                    [4, 10]           1,290\n",
      "          Softmax-18                    [4, 10]               0\n",
      "================================================================\n",
      "Total params: 591,914\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.64\n",
      "Params size (MB): 2.26\n",
      "Estimated Total Size (MB): 7.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model = net, input_size = (3, 32, 32), batch_size = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=net.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1  2000] loss: 1.927  time: 16.891s\n",
      "[1  4000] loss: 1.929  time: 14.305s\n",
      "[1  6000] loss: 1.929  time: 14.242s\n",
      "[1  8000] loss: 1.927  time: 14.063s\n",
      "[1 10000] loss: 1.921  time: 15.137s\n",
      "[1 12000] loss: 1.919  time: 16.550s\n",
      "[2  2000] loss: 2.389  time: 18.905s\n",
      "[2  4000] loss: 1.909  time: 15.857s\n",
      "[2  6000] loss: 1.901  time: 16.594s\n",
      "[2  8000] loss: 1.911  time: 15.210s\n",
      "[2 10000] loss: 1.902  time: 14.481s\n",
      "[2 12000] loss: 1.909  time: 16.202s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # 打印log信息\n",
    "       \n",
    "        running_loss += loss.data\n",
    "        if i % 2000 == 1999:  # 每2000个batch打印一次训练信息\n",
    "            print('[%d %5d] loss: %.3f  time: %.3fs' % (epoch+1, i+1, running_loss/2000, time.time()-start_time))\n",
    "            running_loss = 0\n",
    "            start_time = time.time()\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 5451, total: 10000\n",
      "整个测试集中的准确率为 54.51%\n"
     ]
    }
   ],
   "source": [
    "# 整个测试集上效果\n",
    "total = 0  # 总共的图片数\n",
    "correct = 0  # 正确的图片数\n",
    "for images, labels in test_loader:\n",
    "    outputs = net(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += predicted.size()[0]  # 加4\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "print('correct: %d, total: %d' %(correct, total))\n",
    "print('整个测试集中的准确率为 %.2f%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
