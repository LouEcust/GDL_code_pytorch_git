{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "show = tv.transforms.ToPILImage()  # 将Tensor转化为Image\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(),  # 转为Tensor\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化\n",
    "                                ])\n",
    "# 训练集\n",
    "train_set = tv.datasets.CIFAR10(root='/home/new1006/ljh/data/cifar-10-python',\n",
    "                                train=True,\n",
    "                                download=True,\n",
    "                                transform=transform)\n",
    "\n",
    "train_loader =torch.utils.data.DataLoader(train_set,\n",
    "                                          batch_size=64,  # 4\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True,\n",
    "                                          num_workers=4)\n",
    "\n",
    "# 测试集\n",
    "test_set = tv.datasets.CIFAR10(root='/home/new1006/ljh/data/cifar-10-python',\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=transform)\n",
    "  \n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=64,  # 4\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True)\n",
    "#                                           num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: E:\\Data\\dataSet\\cifar-10-python\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"输入为3通道的网络\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        cba1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "        cba2 = nn.Sequential(\n",
    "                nn.Conv2d(32, 32, 3, 2, 1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "        cba3 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, 3, 1, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "        cba4 = nn.Sequential(\n",
    "                nn.Conv2d(64, 64, 3, 2, 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU()\n",
    "                )\n",
    "        \n",
    "#         self.moudlelist_features = nn.ModuleList([cba1, cba2, cba3, cba4])  # 方法一\n",
    "        \n",
    "        features = [cba1, cba2, cba3, cba4]  # 方法二\n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                    nn.Linear(4096, 128),\n",
    "                    nn.BatchNorm1d(128),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(128, 10),\n",
    "                    nn.Softmax(dim=1)\n",
    "                    ) \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = self.moudlelist_features(x)  # 会报错，Module_List没有实现forward()方法\n",
    "#         for model in self.moudlelist_features:  # 方法一\n",
    "#             x = model(x)\n",
    "        \n",
    "        x = self.features(x)  # 方法二\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)  # 按照Batch形式排列成[Batch, C*W*H]\n",
    "#         x = nn.Linear(in_features=x.size()[-1], out_features=128)(x)  # 将模型放到cuda上时，在forward()中初始化层会报错；cpu上没问题\n",
    "#         x = nn.functional.linear(input=x, weight=torch.randn(128, x.size()[-1]), bias=torch.randn(128))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将模型数据放入cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device  # 判断模型位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cuda')\n",
    "net = net.to(device)  # 整个式子等价与net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(64, 3, 32, 32)   # 判断数据位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用torchsummay.summary展示层结构 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight torch.Size([32, 3, 3, 3])\n",
      "features.0.0.bias torch.Size([32])\n",
      "features.0.1.weight torch.Size([32])\n",
      "features.0.1.bias torch.Size([32])\n",
      "features.1.0.weight torch.Size([32, 32, 3, 3])\n",
      "features.1.0.bias torch.Size([32])\n",
      "features.1.1.weight torch.Size([32])\n",
      "features.1.1.bias torch.Size([32])\n",
      "features.2.0.weight torch.Size([64, 32, 3, 3])\n",
      "features.2.0.bias torch.Size([64])\n",
      "features.2.1.weight torch.Size([64])\n",
      "features.2.1.bias torch.Size([64])\n",
      "features.3.0.weight torch.Size([64, 64, 3, 3])\n",
      "features.3.0.bias torch.Size([64])\n",
      "features.3.1.weight torch.Size([64])\n",
      "features.3.1.bias torch.Size([64])\n",
      "classifier.0.weight torch.Size([128, 4096])\n",
      "classifier.0.bias torch.Size([128])\n",
      "classifier.1.weight torch.Size([128])\n",
      "classifier.1.bias torch.Size([128])\n",
      "classifier.4.weight torch.Size([10, 128])\n",
      "classifier.4.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, p in net.named_parameters():\n",
    "    print(name, p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [64, 32, 32, 32]             896\n",
      "       BatchNorm2d-2           [64, 32, 32, 32]              64\n",
      "         LeakyReLU-3           [64, 32, 32, 32]               0\n",
      "            Conv2d-4           [64, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-5           [64, 32, 16, 16]              64\n",
      "         LeakyReLU-6           [64, 32, 16, 16]               0\n",
      "            Conv2d-7           [64, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-8           [64, 64, 16, 16]             128\n",
      "         LeakyReLU-9           [64, 64, 16, 16]               0\n",
      "           Conv2d-10             [64, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11             [64, 64, 8, 8]             128\n",
      "        LeakyReLU-12             [64, 64, 8, 8]               0\n",
      "           Linear-13                  [64, 128]         524,416\n",
      "      BatchNorm1d-14                  [64, 128]             256\n",
      "        LeakyReLU-15                  [64, 128]               0\n",
      "          Dropout-16                  [64, 128]               0\n",
      "           Linear-17                   [64, 10]           1,290\n",
      "          Softmax-18                   [64, 10]               0\n",
      "================================================================\n",
      "Total params: 591,914\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 90.26\n",
      "Params size (MB): 2.26\n",
      "Estimated Total Size (MB): 93.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model = net, input_size = (3, 32, 32), batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [4, 32, 32, 32]             896\n",
      "       BatchNorm2d-2            [4, 32, 32, 32]              64\n",
      "         LeakyReLU-3            [4, 32, 32, 32]               0\n",
      "            Conv2d-4            [4, 32, 16, 16]           9,248\n",
      "       BatchNorm2d-5            [4, 32, 16, 16]              64\n",
      "         LeakyReLU-6            [4, 32, 16, 16]               0\n",
      "            Conv2d-7            [4, 64, 16, 16]          18,496\n",
      "       BatchNorm2d-8            [4, 64, 16, 16]             128\n",
      "         LeakyReLU-9            [4, 64, 16, 16]               0\n",
      "           Conv2d-10              [4, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-11              [4, 64, 8, 8]             128\n",
      "        LeakyReLU-12              [4, 64, 8, 8]               0\n",
      "           Linear-13                   [4, 128]         524,416\n",
      "      BatchNorm1d-14                   [4, 128]             256\n",
      "        LeakyReLU-15                   [4, 128]               0\n",
      "          Dropout-16                   [4, 128]               0\n",
      "           Linear-17                    [4, 10]           1,290\n",
      "          Softmax-18                    [4, 10]               0\n",
      "================================================================\n",
      "Total params: 591,914\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.64\n",
      "Params size (MB): 2.26\n",
      "Estimated Total Size (MB): 7.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model = net, input_size = (3, 32, 32), batch_size = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=net.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1   260] loss: 1.587  time: 2.827s\n",
      "[1   520] loss: 1.590  time: 2.700s\n",
      "[1   780] loss: 1.599  time: 2.670s\n",
      "[2   260] loss: 1.587  time: 2.867s\n",
      "[2   520] loss: 1.593  time: 2.570s\n",
      "[2   780] loss: 1.592  time: 2.604s\n",
      "[3   260] loss: 1.584  time: 2.942s\n",
      "[3   520] loss: 1.581  time: 2.692s\n",
      "[3   780] loss: 1.590  time: 2.687s\n",
      "[4   260] loss: 1.582  time: 2.905s\n",
      "[4   520] loss: 1.583  time: 2.639s\n",
      "[4   780] loss: 1.589  time: 2.639s\n",
      "[5   260] loss: 1.580  time: 2.893s\n",
      "[5   520] loss: 1.580  time: 2.624s\n",
      "[5   780] loss: 1.579  time: 2.609s\n",
      "[6   260] loss: 1.577  time: 2.853s\n",
      "[6   520] loss: 1.573  time: 2.644s\n",
      "[6   780] loss: 1.580  time: 2.637s\n",
      "[7   260] loss: 1.573  time: 2.901s\n",
      "[7   520] loss: 1.570  time: 2.653s\n",
      "[7   780] loss: 1.579  time: 2.665s\n",
      "[8   260] loss: 1.569  time: 2.978s\n",
      "[8   520] loss: 1.573  time: 2.660s\n",
      "[8   780] loss: 1.570  time: 2.610s\n",
      "[9   260] loss: 1.568  time: 2.911s\n",
      "[9   520] loss: 1.568  time: 2.708s\n",
      "[9   780] loss: 1.568  time: 2.685s\n",
      "[10   260] loss: 1.567  time: 2.486s\n",
      "[10   520] loss: 1.566  time: 2.207s\n",
      "[10   780] loss: 1.566  time: 2.688s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "start_time = time.time()\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() # 打印log信息\n",
    "       \n",
    "        running_loss += loss.data\n",
    "        if i % 260 == 259:  # 每2000个batch打印一次训练信息\n",
    "            print('[%d %5d] loss: %.3f  time: %.3fs' % (epoch+1, i+1, running_loss/260, time.time()-start_time))\n",
    "            running_loss = 0\n",
    "            start_time = time.time()\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 7370, total: 9984\n",
      "整个测试集中的准确率为 73.82%\n"
     ]
    }
   ],
   "source": [
    "# 整个测试集上效果\n",
    "total = 0  # 总共的图片数\n",
    "correct = 0  # 正确的图片数\n",
    "for images, labels in test_loader:\n",
    "    outputs = net(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += predicted.size()[0]  # 加4\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "print('correct: %d, total: %d' %(correct, total))\n",
    "print('整个测试集中的准确率为 %.2f%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_10",
   "language": "python",
   "name": "jupyter_kernel_py110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
