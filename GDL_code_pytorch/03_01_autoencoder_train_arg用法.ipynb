{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from models.Autoencoder import Autoencoder\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "train_ds = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_dl = t.utils.data.DataLoader(dataset=train_ds, batch_size=bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shapeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0][None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (enc_conv_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (4): Flatten()\n",
       "    (5): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  )\n",
       "  (dec_conv_layers): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=2304, bias=True)\n",
       "    (1): View()\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = t.device('cuda') if t.cuda.is_available() else 'cpu'\n",
    "model = Autoencoder(train_ds[0][0][None], in_c=1, enc_out_c=[32, 64, 64, 64],\n",
    "                    enc_ks=[3, 3, 3, 3], enc_pads=[1, 1, 0, 1], enc_strides=[1, 2, 2, 1],\n",
    "                    dec_out_c=[64, 64, 32, 1], dec_ks=[3, 3, 3, 3], dec_strides=[1, 2, 2, 1],\n",
    "                    dec_pads=[1, 0, 1, 1], dec_op_pads=[0, 1, 1, 0], z_dim=2)\n",
    "model.cuda(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         LeakyReLU-2           [-1, 32, 28, 28]               0\n",
      "       BatchNorm2d-3           [-1, 32, 28, 28]              64\n",
      "           Dropout-4           [-1, 32, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 14, 14]          18,496\n",
      "         LeakyReLU-6           [-1, 64, 14, 14]               0\n",
      "       BatchNorm2d-7           [-1, 64, 14, 14]             128\n",
      "           Dropout-8           [-1, 64, 14, 14]               0\n",
      "            Conv2d-9             [-1, 64, 6, 6]          36,928\n",
      "        LeakyReLU-10             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-11             [-1, 64, 6, 6]             128\n",
      "          Dropout-12             [-1, 64, 6, 6]               0\n",
      "           Conv2d-13             [-1, 64, 6, 6]          36,928\n",
      "        LeakyReLU-14             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-15             [-1, 64, 6, 6]             128\n",
      "          Dropout-16             [-1, 64, 6, 6]               0\n",
      "          Flatten-17                 [-1, 2304]               0\n",
      "           Linear-18                    [-1, 2]           4,610\n",
      "           Linear-19                 [-1, 2304]           6,912\n",
      "             View-20             [-1, 64, 6, 6]               0\n",
      "  ConvTranspose2d-21             [-1, 64, 6, 6]          36,928\n",
      "        LeakyReLU-22             [-1, 64, 6, 6]               0\n",
      "      BatchNorm2d-23             [-1, 64, 6, 6]             128\n",
      "          Dropout-24             [-1, 64, 6, 6]               0\n",
      "  ConvTranspose2d-25           [-1, 64, 14, 14]          36,928\n",
      "        LeakyReLU-26           [-1, 64, 14, 14]               0\n",
      "      BatchNorm2d-27           [-1, 64, 14, 14]             128\n",
      "          Dropout-28           [-1, 64, 14, 14]               0\n",
      "  ConvTranspose2d-29           [-1, 32, 28, 28]          18,464\n",
      "        LeakyReLU-30           [-1, 32, 28, 28]               0\n",
      "      BatchNorm2d-31           [-1, 32, 28, 28]              64\n",
      "          Dropout-32           [-1, 32, 28, 28]               0\n",
      "  ConvTranspose2d-33            [-1, 1, 28, 28]             289\n",
      "          Sigmoid-34            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 197,571\n",
      "Trainable params: 197,571\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.57\n",
      "Params size (MB): 0.75\n",
      "Estimated Total Size (MB): 3.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model=model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4010, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0887, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0781, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                              | 1/20 [00:14<04:26, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0572, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 2/20 [00:28<04:12, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0579, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0556, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                      | 3/20 [00:39<03:40, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0509, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 4/20 [00:51<03:19, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0529, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 5/20 [01:03<03:03, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0504, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 6/20 [01:15<02:49, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████████████                                                      | 7/20 [01:26<02:35, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [01:40<02:28, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [01:52<02:14, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 10/20 [02:04<02:01, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████                                     | 11/20 [02:15<01:48, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0473, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [02:29<01:38, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▎                            | 13/20 [02:43<01:31, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0462, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 14/20 [02:56<01:17, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [03:08<01:03, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0476, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 16/20 [03:22<00:51, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0470, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 17/20 [03:34<00:38, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [03:46<00:25, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [03:58<00:12, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:10<00:00, 12.55s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = t.optim.Adam(model.parameters(), lr=5e-4, betas=(.9, .99), weight_decay=1e-2)\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(20)):\n",
    "    if epoch == 10:\n",
    "        optimizer = t.optim.Adam(model.parameters(), lr=2e-4, betas=(.9, .99), weight_decay=1e-2)\n",
    "    for i, (data, _) in enumerate(train_dl):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = F.mse_loss(pred, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 33 == 0:\n",
    "            print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "t.save(model.state_dict(), 'models/state_dicts/03_01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def f(*arg, **args) 以及 f(*arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out_c=[1, 32, 64, 64, 64]; enc_ks=[3,3,3,3]; enc_strides=[1,2,2,1]; enc_pads=[1,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 32, 3, 1, 1), (32, 64, 3, 2, 1), (64, 64, 3, 2, 0), (64, 64, 3, 1, 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(enc_out_c[0:], enc_out_c[1:], enc_ks, enc_strides, enc_pads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a [Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
      "e [Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), LeakyReLU(negative_slope=0.01), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Dropout(p=0.25, inplace=False)]\n",
      "a [Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))]\n",
      "e [Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), LeakyReLU(negative_slope=0.01), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Dropout(p=0.25, inplace=False)]\n",
      "a [Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))]\n",
      "e [Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2)), LeakyReLU(negative_slope=0.01), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Dropout(p=0.25, inplace=False)]\n",
      "a [Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]\n",
      "e [Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), LeakyReLU(negative_slope=0.01), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Dropout(p=0.25, inplace=False)]\n"
     ]
    }
   ],
   "source": [
    "for in_c_, out_c, ks, stride, pad in zip(enc_out_c[0:], enc_out_c[1:], enc_ks, enc_strides, enc_pads):\n",
    "    enc_conv_layer = []\n",
    "    enc_conv_layer.append(nn.Conv2d(in_c_, out_c, ks, stride, padding=pad))\n",
    "    print('a', enc_conv_layer)\n",
    "    enc_conv_layer.extend([nn.LeakyReLU(), nn.BatchNorm2d(out_c), nn.Dropout(.25)])\n",
    "    print('e', enc_conv_layer)\n",
    "#     enc_conv_layers.append(nn.Sequential(*enc_conv_layer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args):\n",
    "    print(args)\n",
    "    print('len =', len(args))\n",
    "#     print(args[0])\n",
    "#     print(isinstance(args[0], OrderedDict))\n",
    "#     print(type(args))\n",
    "    for k, v in enumerate(args):\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "A = OrderedDict([           #orderdict按照建造时候的顺序进行存储\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1', Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))),\n",
       "             ('relu1', ReLU()),\n",
       "             ('conv2', Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))),\n",
       "             ('relu2', ReLU())])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('conv1', Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))), ('relu1', ReLU()), ('conv2', Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))), ('relu2', ReLU())]),)\n",
      "len = 1\n",
      "0 OrderedDict([('conv1', Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))), ('relu1', ReLU()), ('conv2', Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))), ('relu2', ReLU())])\n"
     ]
    }
   ],
   "source": [
    "f(A)  # 形参中(*OrderedDict)将OrderedDict组合成一个元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = {'a':1, 'b':2, 'c':3, 'd':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'a': 1, 'b': 2, 'c': 3, 'd': 4},)\n",
      "len = 1\n",
      "0 {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n"
     ]
    }
   ],
   "source": [
    "f(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'd': 4}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ['a', 'b', 'c', 'd']  # C = ('a', 'b', 'c', 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', 'b', 'c', 'd'),)\n",
      "len = 1\n",
      "0 ('a', 'b', 'c', 'd')\n"
     ]
    }
   ],
   "source": [
    "f(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c', 'd')\n",
      "len = 4\n",
      "0 a\n",
      "1 b\n",
      "2 c\n",
      "3 d\n"
     ]
    }
   ],
   "source": [
    "f(*C)  # 实参*C将列表C解包,然后f函数*arg形参又将解包元素打包成元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " LeakyReLU(negative_slope=0.01),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout(p=0.25, inplace=False)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) LeakyReLU(negative_slope=0.01) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) Dropout(p=0.25, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "print(*enc_conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), LeakyReLU(negative_slope=0.01), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Dropout(p=0.25, inplace=False))\n",
      "len = 4\n",
      "0 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "1 LeakyReLU(negative_slope=0.01)\n",
      "2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "3 Dropout(p=0.25, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "f(*enc_conv_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
